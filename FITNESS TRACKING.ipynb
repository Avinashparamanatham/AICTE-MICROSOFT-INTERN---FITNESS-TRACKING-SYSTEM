{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calories Prediction MSE: 18.8510306\n",
      "\n",
      "Heart Rate Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        67.0       0.00      0.00      0.00         1\n",
      "        70.0       0.00      0.00      0.00         2\n",
      "        71.0       0.00      0.00      0.00         2\n",
      "        72.0       0.40      0.40      0.40         5\n",
      "        73.0       0.00      0.00      0.00         7\n",
      "        74.0       0.00      0.00      0.00         7\n",
      "        75.0       0.08      0.09      0.09        11\n",
      "        76.0       0.19      0.17      0.18        18\n",
      "        77.0       0.40      0.27      0.32        22\n",
      "        78.0       0.62      0.54      0.58        28\n",
      "        79.0       0.52      0.68      0.59        38\n",
      "        80.0       0.66      0.69      0.68        36\n",
      "        81.0       0.83      0.83      0.83        41\n",
      "        82.0       0.90      0.78      0.83        67\n",
      "        83.0       0.86      0.94      0.89        63\n",
      "        84.0       0.89      0.97      0.93        69\n",
      "        85.0       0.94      0.92      0.93        85\n",
      "        86.0       0.88      0.94      0.91        79\n",
      "        87.0       0.94      0.98      0.96       102\n",
      "        88.0       0.97      0.96      0.97        80\n",
      "        89.0       0.96      0.96      0.96       102\n",
      "        90.0       0.99      0.98      0.99       103\n",
      "        91.0       0.95      0.97      0.96       109\n",
      "        92.0       0.90      0.96      0.93        92\n",
      "        93.0       0.97      0.96      0.96        97\n",
      "        94.0       0.97      0.97      0.97       111\n",
      "        95.0       0.98      0.98      0.98       107\n",
      "        96.0       0.99      0.99      0.99        93\n",
      "        97.0       0.96      0.97      0.97       109\n",
      "        98.0       0.96      0.98      0.97       112\n",
      "        99.0       0.98      0.99      0.98        91\n",
      "       100.0       0.96      0.95      0.95        97\n",
      "       101.0       0.91      0.98      0.94       104\n",
      "       102.0       0.99      0.94      0.97        89\n",
      "       103.0       0.96      0.96      0.96        94\n",
      "       104.0       1.00      0.93      0.97        89\n",
      "       105.0       0.95      0.97      0.96        99\n",
      "       106.0       0.96      0.97      0.97        71\n",
      "       107.0       0.94      0.99      0.97        86\n",
      "       108.0       0.91      0.98      0.94        82\n",
      "       109.0       0.84      0.82      0.83        56\n",
      "       110.0       0.79      0.85      0.81        52\n",
      "       111.0       0.68      0.75      0.71        48\n",
      "       112.0       0.62      0.68      0.65        41\n",
      "       113.0       0.42      0.42      0.42        31\n",
      "       114.0       0.50      0.42      0.46        26\n",
      "       115.0       0.25      0.16      0.19        19\n",
      "       116.0       0.50      0.29      0.36         7\n",
      "       117.0       0.33      0.10      0.15        10\n",
      "       118.0       0.00      0.00      0.00         3\n",
      "       119.0       0.00      0.00      0.00         5\n",
      "       120.0       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.89      3000\n",
      "   macro avg       0.68      0.66      0.67      3000\n",
      "weighted avg       0.89      0.89      0.89      3000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\avinash\\.anaconda\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\avinash\\.anaconda\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\avinash\\.anaconda\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets processed and models saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, classification_report\n",
    "\n",
    "class FitnessDataProcessor:\n",
    "    def __init__(self, exercise_file='exercise.csv', calories_file='calories.csv'):\n",
    "        self.exercise_file = exercise_file\n",
    "        self.calories_file = calories_file\n",
    "        \n",
    "    def load_exercise_dataset(self):\n",
    "        \"\"\"\n",
    "        Load exercise dataset with specified columns\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Read the dataset\n",
    "            df = pd.read_csv(self.exercise_file)\n",
    "            \n",
    "            # Validate columns\n",
    "            required_columns = [\n",
    "                'User_ID', 'Gender', 'Age', 'Height', \n",
    "                'Weight', 'Duration', 'Heart_Rate', 'Body_Temp'\n",
    "            ]\n",
    "            \n",
    "            # Check if all required columns exist\n",
    "            missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "            if missing_columns:\n",
    "                raise ValueError(f\"Missing columns: {missing_columns}\")\n",
    "            \n",
    "            # Select only required columns\n",
    "            df = df[required_columns]\n",
    "            \n",
    "            # Basic data cleaning\n",
    "            numeric_columns = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']\n",
    "            for col in numeric_columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            \n",
    "            # Handle missing values\n",
    "            df.dropna(inplace=True)\n",
    "            \n",
    "            return df\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading exercise dataset: {e}\")\n",
    "            return self.create_sample_exercise_dataset()\n",
    "\n",
    "    def load_calories_dataset(self):\n",
    "        \"\"\"\n",
    "        Load calories dataset with specified columns\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Read the dataset\n",
    "            df = pd.read_csv(self.calories_file)\n",
    "            \n",
    "            # Validate columns\n",
    "            required_columns = ['User_ID', 'Calories']\n",
    "            \n",
    "            # Check if all required columns exist\n",
    "            missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "            if missing_columns:\n",
    "                raise ValueError(f\"Missing columns: {missing_columns}\")\n",
    "            \n",
    "            # Select only required columns\n",
    "            df = df[required_columns]\n",
    "            \n",
    "            # Convert Calories to numeric\n",
    "            df['Calories'] = pd.to_numeric(df['Calories'], errors='coerce')\n",
    "            \n",
    "            # Handle missing values\n",
    "            df.dropna(inplace=True)\n",
    "            \n",
    "            return df\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading calories dataset: {e}\")\n",
    "            return self.create_sample_calories_dataset()\n",
    "\n",
    "    def create_sample_exercise_dataset(self):\n",
    "        \"\"\"\n",
    "        Create a sample exercise dataset when actual data is not available\n",
    "        \"\"\"\n",
    "        return pd.DataFrame({\n",
    "            'User_ID': range(1, 101),\n",
    "            'Gender': np.random.choice(['Male', 'Female'], 100),\n",
    "            'Age': np.random.randint(18, 65, 100),\n",
    "            'Height': np.random.uniform(150, 200, 100),\n",
    "            'Weight': np.random.uniform(50, 100, 100),\n",
    "            'Duration': np.random.uniform(30, 120, 100),\n",
    "            'Heart_Rate': np.random.randint(60, 180, 100),\n",
    "            'Body_Temp': np.random.uniform(36.5, 38.5, 100)\n",
    "        })\n",
    "\n",
    "    def create_sample_calories_dataset(self):\n",
    "        \"\"\"\n",
    "        Create a sample calories dataset when actual data is not available\n",
    "        \"\"\"\n",
    "        return pd.DataFrame({\n",
    "            'User_ID': range(1, 101),\n",
    "            'Calories': np.random.randint(200, 800, 100)\n",
    "        })\n",
    "\n",
    "    def merge_datasets(self, exercise_df, calories_df):\n",
    "        \"\"\"\n",
    "        Merge exercise and calories datasets\n",
    "        \"\"\"\n",
    "        return pd.merge(exercise_df, calories_df, on='User_ID')\n",
    "\n",
    "    def preprocess_data(self, merged_df):\n",
    "        \"\"\"\n",
    "        Preprocess merged dataset for machine learning\n",
    "        \"\"\"\n",
    "        # Create a copy of the dataframe\n",
    "        df_encoded = merged_df.copy()\n",
    "        \n",
    "        # One-hot encode Gender using pandas get_dummies\n",
    "        df_encoded = pd.get_dummies(df_encoded, columns=['Gender'], prefix='Gender')\n",
    "        \n",
    "        # Ensure all required columns exist\n",
    "        required_features = [\n",
    "            'Age', 'Height', 'Weight', 'Duration', \n",
    "            'Heart_Rate', 'Body_Temp', \n",
    "            'Gender_Male', 'Gender_Female'\n",
    "        ]\n",
    "        \n",
    "        # Add missing columns with default 0 if not present\n",
    "        for col in required_features:\n",
    "            if col not in df_encoded.columns:\n",
    "                df_encoded[col] = 0\n",
    "        \n",
    "        # Select features and targets\n",
    "        X = df_encoded[required_features]\n",
    "        y_calories = df_encoded['Calories']\n",
    "        y_heart_rate = df_encoded['Heart_Rate']\n",
    "        \n",
    "        # Split data\n",
    "        X_train_calories, X_test_calories, y_train_calories, y_test_calories = train_test_split(\n",
    "            X, y_calories, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        X_train_hr, X_test_hr, y_train_hr, y_test_hr = train_test_split(\n",
    "            X, y_heart_rate, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled_calories = scaler.fit_transform(X_train_calories)\n",
    "        X_test_scaled_calories = scaler.transform(X_test_calories)\n",
    "        \n",
    "        X_train_scaled_hr = scaler.fit_transform(X_train_hr)\n",
    "        X_test_scaled_hr = scaler.transform(X_test_hr)\n",
    "        \n",
    "        return {\n",
    "            'X_train_calories': X_train_scaled_calories,\n",
    "            'X_test_calories': X_test_scaled_calories,\n",
    "            'y_train_calories': y_train_calories,\n",
    "            'y_test_calories': y_test_calories,\n",
    "            'X_train_hr': X_train_scaled_hr,\n",
    "            'X_test_hr': X_test_scaled_hr,\n",
    "            'y_train_hr': y_train_hr,\n",
    "            'y_test_hr': y_test_hr,\n",
    "            'scaler': scaler\n",
    "        }\n",
    "\n",
    "    def train_and_save_models(self, prepared_data):\n",
    "        \"\"\"\n",
    "        Train machine learning models and save them\n",
    "        \"\"\"\n",
    "        # Calories Prediction Model (Regression)\n",
    "        calories_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        calories_model.fit(\n",
    "            prepared_data['X_train_calories'], \n",
    "            prepared_data['y_train_calories']\n",
    "        )\n",
    "        \n",
    "        # Heart Rate Classification Model\n",
    "        hr_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        hr_model.fit(\n",
    "            prepared_data['X_train_hr'], \n",
    "            prepared_data['y_train_hr']\n",
    "        )\n",
    "        \n",
    "        # Evaluate Models\n",
    "        calories_pred = calories_model.predict(prepared_data['X_test_calories'])\n",
    "        hr_pred = hr_model.predict(prepared_data['X_test_hr'])\n",
    "        \n",
    "        print(\"Calories Prediction MSE:\", \n",
    "              mean_squared_error(prepared_data['y_test_calories'], calories_pred))\n",
    "        print(\"\\nHeart Rate Classification Report:\")\n",
    "        print(classification_report(\n",
    "            prepared_data['y_test_hr'], \n",
    "            hr_pred\n",
    "        ))\n",
    "        \n",
    "        # Save models using pickle\n",
    "        with open('calories_model.pkl', 'wb') as f:\n",
    "            pickle.dump(calories_model, f)\n",
    "        \n",
    "        with open('heart_rate_model.pkl', 'wb') as f:\n",
    "            pickle.dump(hr_model, f)\n",
    "        \n",
    "        # Save scaler\n",
    "        with open('scaler.pkl', 'wb') as f:\n",
    "            pickle.dump(prepared_data['scaler'], f)\n",
    "        \n",
    "        return calories_model, hr_model\n",
    "\n",
    "    def process_datasets(self):\n",
    "        \"\"\"\n",
    "        Main method to process datasets\n",
    "        \"\"\"\n",
    "        # Load datasets\n",
    "        exercise_df = self.load_exercise_dataset()\n",
    "        calories_df = self.load_calories_dataset()\n",
    "        \n",
    "        # Merge datasets\n",
    "        merged_df = self.merge_datasets(exercise_df, calories_df)\n",
    "        \n",
    "        # Preprocess data\n",
    "        prepared_data = self.preprocess_data(merged_df)\n",
    "        \n",
    "        # Train and save models\n",
    "        self.train_and_save_models(prepared_data)\n",
    "        \n",
    "        return merged_df, prepared_data\n",
    "\n",
    "# Main execution\n",
    "if __name__ == '__main__':\n",
    "    processor = FitnessDataProcessor()\n",
    "    merged_df, prepared_data = processor.process_datasets()\n",
    "    print(\"Datasets processed and models saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
